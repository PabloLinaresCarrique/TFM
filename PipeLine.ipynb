{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, FunctionTransformer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import pickle"
      ],
      "metadata": {
        "id": "2ndRPxDIcoC9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para manejar la transformación de la columna 'Timestamp'\n",
        "def transformar_fecha(df):\n",
        "    df['Timestamp'] = pd.to_datetime(df['Timestamp'], errors='coerce')\n",
        "    df['Year'] = df['Timestamp'].dt.year\n",
        "    df['Month'] = df['Timestamp'].dt.month\n",
        "    df['Day'] = df['Timestamp'].dt.day\n",
        "    df['Hour'] = df['Timestamp'].dt.hour\n",
        "    df['Minute'] = df['Timestamp'].dt.minute\n",
        "    return df.drop(columns=['Timestamp'])\n"
      ],
      "metadata": {
        "id": "rTGvapR0cpFt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir las columnas categóricas y numéricas\n",
        "categorical_features = ['Account2', 'Receiving Currency', 'Payment Currency', 'Payment Format', 'Account4']\n",
        "numeric_features = ['Year', 'Month', 'Day', 'Hour', 'Minute']"
      ],
      "metadata": {
        "id": "3KFOwggGcuSP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
        "        ('num', SimpleImputer(strategy='mean'), numeric_features)  # Imputación para valores numéricos\n",
        "    ])"
      ],
      "metadata": {
        "id": "8Bs0IzO6drif"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline completo\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('fecha_transform', FunctionTransformer(transformar_fecha)),  # Función personalizada para transformar fechas\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced'))\n",
        "])"
      ],
      "metadata": {
        "id": "BdgvrPbxdtcJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/Thesis/export.csv')"
      ],
      "metadata": {
        "id": "gLsIBeEIdwrA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_positivos = df[df['Is Laundering'] == 1]\n",
        "df_negativos = df[df['Is Laundering'] == 0]\n",
        "n_positivos = len(df_positivos)\n",
        "n_negativos = int(1.5 * n_positivos)\n",
        "df_negativos_reducidos = df_negativos.sample(n=n_negativos, random_state=42)\n",
        "df_balanceado = pd.concat([df_positivos, df_negativos_reducidos])\n",
        "df_balanceado = df_balanceado.sample(frac=1, random_state=42).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "_DFea-yLd2OF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_balanceado.drop('Is Laundering', axis=1)\n",
        "y = df_balanceado['Is Laundering']\n",
        "\n",
        "# Dividir el conjunto de datos en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "YW5F1Bt7d5fM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "ZNqG-Bp7d-HP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8QckaFuFbVv"
      },
      "outputs": [],
      "source": [
        "# Hacer predicciones y evaluar el modelo\n",
        "y_pred = pipeline.predict(X_test)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Guardar el pipeline completo en un archivo PKL\n",
        "pipeline_path = '/content/drive/My Drive/Thesis/random_forest_pipeline.pkl'\n",
        "with open(pipeline_path, 'wb') as file:\n",
        "    pickle.dump(pipeline, file)\n"
      ]
    }
  ]
}