{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Notebook alternativo al Docker y SQL automatizado:"],"metadata":{"id":"k6uEZ5KDZzVC"}},{"cell_type":"markdown","source":["Este notebook funciona como una alternativa a la prepración de los datos para utilizarlos en la plataforma."],"metadata":{"id":"FSwjcaViaOY-"}},{"cell_type":"markdown","source":["---"],"metadata":{"id":"SNFY5YRlbHeT"}},{"cell_type":"markdown","source":["## Funcionamiento de la herramienta:"],"metadata":{"id":"hpL8-tz3bLMh"}},{"cell_type":"markdown","source":["La herramienta esta con el dataset previamente cargado y con una ruta establecida hacia una carpeta de drive por lo que NO se debe de realizar ninguna modificación sobre el mismo simplemente correr el código."],"metadata":{"id":"iRrQmzgjbPTm"}},{"cell_type":"markdown","source":["---"],"metadata":{"id":"2hg1uvqUcahK"}},{"cell_type":"markdown","source":["## Construcción del código:"],"metadata":{"id":"Cv0wNGukcPkT"}},{"cell_type":"markdown","source":["Importación de librerias"],"metadata":{"id":"uwGLIBmnciKV"}},{"cell_type":"code","execution_count":8,"metadata":{"id":"62cHypfdNpyU","executionInfo":{"status":"ok","timestamp":1726740478355,"user_tz":-120,"elapsed":948,"user":{"displayName":"CortexAi","userId":"17341151088591981016"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import pickle\n","import datetime\n","import gdown"]},{"cell_type":"markdown","source":["Se hace una conexión con drive y se seleeciona directamente el dataset comentado anteriormente:\n","*  HI-Small_Trans.csv\n","\n","A su vez, se carga el modelo guardado en un archivo .pkl, llamado\n","*  model_xgb_optimized.pkl"],"metadata":{"id":"yV4YtHrlcux8"}},{"cell_type":"code","source":["# Descargar el dataset utilizando gdown\n","file_id = '1fDw0plQy898cw5aPZ8qBfP61djO6ssDH'\n","gdown.download(f'https://drive.google.com/uc?export=download&id={file_id}', 'hi_small.csv', quiet=False)\n","\n","# Descargar el modelo utilizando gdown\n","model_file_id = '1p593_b7-TkBAFzfOoEuXfg3jsDD1jyjw'\n","gdown.download(f'https://drive.google.com/uc?export=download&id={model_file_id}', 'model_xgb_optimized.pkl', quiet=False)\n","\n","# Descargar los label encoders utilizando gdown\n","encoders_file_id = '1fi9D8-UYu541eiHGDWugnat1Vavd9a3h'\n","gdown.download(f'https://drive.google.com/uc?export=download&id={encoders_file_id}', 'label_encoders1.pkl', quiet=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":261},"id":"BnZrz8n5NrtD","outputId":"171ef96b-daf1-4edf-cddc-f5259fa81ef7","executionInfo":{"status":"ok","timestamp":1726740512953,"user_tz":-120,"elapsed":24142,"user":{"displayName":"CortexAi","userId":"17341151088591981016"}}},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading...\n","From (original): https://drive.google.com/uc?export=download&id=1fDw0plQy898cw5aPZ8qBfP61djO6ssDH\n","From (redirected): https://drive.google.com/uc?export=download&id=1fDw0plQy898cw5aPZ8qBfP61djO6ssDH&confirm=t&uuid=c9b59b40-acc6-48a3-94e6-10b8511a1a35\n","To: /content/hi_small.csv\n","100%|██████████| 476M/476M [00:09<00:00, 49.9MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?export=download&id=1p593_b7-TkBAFzfOoEuXfg3jsDD1jyjw\n","To: /content/model_xgb_optimized.pkl\n","100%|██████████| 923k/923k [00:00<00:00, 91.2MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?export=download&id=1fi9D8-UYu541eiHGDWugnat1Vavd9a3h\n","To: /content/label_encoders.pkl\n","100%|██████████| 71.7M/71.7M [00:00<00:00, 76.1MB/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["'label_encoders.pkl'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["En esta parte, preparamos los datos aplicandole los label encorders al dataset.\n","\n"," Tanto a los positivos como a los negativos, posteriormente los añadimos en el mismo dataset para crear uno único. En este único, aplicamos las predicciones y las reglas SQL predefinidas. Una vez que las tenemos, utilizamos un sistema de prioridades pra los analistas, quedando asi:\n","\n"," El sistema de prioridades quedaría así:\n","\n","*   Prioridad 1: SQL + modelo             1/1\n","*   Prioridad 2:  Solo SQL detecta        1/0\n","*   Prioridad 3: Solo detecta modelo    0/1\n","\n","\n","\n"],"metadata":{"id":"m19cPEVie5aY"}},{"cell_type":"code","source":["\n","# Cargar el dataset y el modelo\n","hi_small = pd.read_csv('hi_small.csv')\n","\n","modelo_path = 'model_xgb_optimized.pkl'\n","with open(modelo_path, 'rb') as file:\n","    model = pickle.load(file)\n","\n","# Preparación de datos para aplicar label encoders\n","hi_small['Timestamp'] = pd.to_datetime(hi_small['Timestamp'])\n","\n","hi_small['Year'] = hi_small['Timestamp'].dt.year\n","hi_small['Month'] = hi_small['Timestamp'].dt.month\n","hi_small['Day'] = hi_small['Timestamp'].dt.day\n","hi_small['Hour'] = hi_small['Timestamp'].dt.hour\n","hi_small['Minute'] = hi_small['Timestamp'].dt.minute\n","\n","hi_small.drop(columns=['Timestamp'], inplace=True)\n","hi_small.rename(columns={'Account': 'Account2', 'Account.1': 'Account4'}, inplace=True)\n","\n","# Cargar los label encoders\n","path_to_encoders = 'label_encoders1.pkl'\n","with open(path_to_encoders, 'rb') as f:\n","    label_encoders = pickle.load(f)\n","\n","# Aplicación de los labels encoders\n","for col, le in label_encoders.items():\n","    if col in hi_small.columns:\n","        hi_small[col] = le.transform(hi_small[col])\n","\n","X = hi_small.drop(columns=['Is Laundering'])\n","predicciones = model.predict(X)\n","\n","# Filtro de predicciones de 1\n","hi_small['predicciones'] = predicciones\n","hi_small_pred_1 = hi_small[hi_small['predicciones'] == 1]\n","\n","# Aplicación inversa de predicciones = 1\n","with open(path_to_encoders, 'rb') as f:\n","    label_encoders = pickle.load(f)\n","for col, le in label_encoders.items():\n","    if col in hi_small_pred_1.columns:\n","        hi_small_pred_1[col] = le.inverse_transform(hi_small_pred_1[col])\n","\n","hi_small_pred_1.rename(columns={'Account2': 'from_account', 'Account4': 'to_account', 'Is Laundering': 'Actual_Is_Laundering', 'predicciones': 'Predicted_Is_Laundering'}, inplace=True)\n","hi_small_pred_1.drop(columns=['Year', 'Month', 'Day', 'Hour', 'Minute'], inplace=True)\n","\n","# Filtro de predicciones de 0\n","hi_small_pred_0 = hi_small[hi_small['predicciones'] == 0]\n","hi_small_pred_0_16000 = hi_small_pred_0.head(16000)\n","\n","# Aplicación inversa de predicciones = 0\n","with open(path_to_encoders, 'rb') as f:\n","    label_encoders = pickle.load(f)\n","for col, le in label_encoders.items():\n","    if col in hi_small_pred_0_16000.columns:\n","        hi_small_pred_0_16000[col] = le.inverse_transform(hi_small_pred_0_16000[col])\n","\n","hi_small_pred_0_16000.rename(columns={'Account2': 'from_account', 'Account4': 'to_account', 'Is Laundering': 'Actual_Is_Laundering', 'predicciones': 'Predicted_Is_Laundering'}, inplace=True)\n","hi_small_pred_0_16000.drop(columns=['Year', 'Month', 'Day', 'Hour', 'Minute'], inplace=True)\n","\n","# Combinación de los dataset\n","combined_df = pd.concat([hi_small_pred_1, hi_small_pred_0_16000])\n","combined_df.columns = combined_df.columns.str.strip().str.replace(' ', '_').str.lower()\n","transactions = combined_df.drop(\"actual_is_laundering\", axis=1)\n","\n","# Reglas de SQL\n","def apply_aml_rules(df):\n","    rules = [\n","        {\n","            \"name\": \"Cash Reporting Circumvention\",\n","            \"condition\": \"(payment_currency in ['Euro', 'US Dollar']) and (payment_format == 'Cash') and (9800 <= amount_paid <= 9999.99)\"\n","        },\n","        {\n","            \"name\": \"Exotic Currencies to Cash\",\n","            \"condition\": \"(payment_currency in ['Shekel', 'Mexican Peso', 'Brazilian Real']) and (payment_format in ['Cheque', 'Cash', 'Wire']) and (amount_paid >= 90000)\"\n","        },\n","        {\n","            \"name\": \"High Value Bitcoin to/from Cash\",\n","            \"condition\": \"((receiving_currency == 'Bitcoin') or (payment_currency == 'Bitcoin')) and (amount_paid > 35000)\"\n","        },\n","        {\n","            \"name\": \"Exotic Currencies to/from Bitcoin\",\n","            \"condition\": \"(((receiving_currency in ['Mexican Peso', 'Ruble']) and (payment_currency == 'Bitcoin')) or ((receiving_currency == 'Bitcoin') and (payment_currency in ['Mexican Peso', 'Ruble']))) and (amount_paid > 150000)\"\n","        },\n","        {\n","            \"name\": \"High Value Cheque Payments\",\n","            \"condition\": \"(payment_format == 'Cheque') and (amount_paid > 1000000)\"\n","        },\n","        {\n","            \"name\": \"High Value Wire Payments\",\n","            \"condition\": \"(payment_format == 'Wire') and (amount_paid > 5000000)\"\n","        }\n","    ]\n","\n","    df['sql_is_laundering'] = 0\n","\n","    for rule in rules:\n","        df.loc[df.eval(rule['condition']), 'sql_is_laundering'] = 1\n","\n","    return df\n","\n","# Aplicación de las reglas sobre el dataset\n","transactions = apply_aml_rules(transactions)\n","\n","# Asignación de las prioridades\n","def assign_priority(row):\n","    if row['predicted_is_laundering'] == 1 and row['sql_is_laundering'] == 0:\n","        return 'Medium Priority'\n","    elif row['predicted_is_laundering'] == 0 and row['sql_is_laundering'] == 1:\n","        return 'Normal Priority'\n","    elif row['predicted_is_laundering'] == 1 and row['sql_is_laundering'] == 1:\n","        return 'High Priority'\n","    else:\n","        return 'Low Priority'\n","\n","transactions['priority'] = transactions.apply(assign_priority, axis=1)\n","transactions_filtered = transactions[(transactions['predicted_is_laundering'] != 0) | (transactions['sql_is_laundering'] != 0)]\n","\n","# Exportar el JSON al local\n","output_json_filename = f'filtered_transactions_{datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.json'\n","transactions_filtered.to_json(output_json_filename, orient='records', lines=False)\n","\n","# Descargar el archivo JSON al local\n","from google.colab import files\n","files.download(output_json_filename)\n","\n","# Confirmación\n","print(f\"El archivo JSON '{output_json_filename}' ha sido generado y descargado.\")\n"],"metadata":{"id":"0c6JPwToSpb5","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"825b2209-effb-41ce-d7ce-6668f4fd5c13","executionInfo":{"status":"ok","timestamp":1726740590615,"user_tz":-120,"elapsed":73664,"user":{"displayName":"CortexAi","userId":"17341151088591981016"}}},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-10-0b9dcdcb6d0c>:42: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  hi_small_pred_1[col] = le.inverse_transform(hi_small_pred_1[col])\n","<ipython-input-10-0b9dcdcb6d0c>:42: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  hi_small_pred_1[col] = le.inverse_transform(hi_small_pred_1[col])\n","<ipython-input-10-0b9dcdcb6d0c>:42: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  hi_small_pred_1[col] = le.inverse_transform(hi_small_pred_1[col])\n","<ipython-input-10-0b9dcdcb6d0c>:42: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  hi_small_pred_1[col] = le.inverse_transform(hi_small_pred_1[col])\n","<ipython-input-10-0b9dcdcb6d0c>:42: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  hi_small_pred_1[col] = le.inverse_transform(hi_small_pred_1[col])\n","<ipython-input-10-0b9dcdcb6d0c>:42: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  hi_small_pred_1[col] = le.inverse_transform(hi_small_pred_1[col])\n","<ipython-input-10-0b9dcdcb6d0c>:42: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  hi_small_pred_1[col] = le.inverse_transform(hi_small_pred_1[col])\n","<ipython-input-10-0b9dcdcb6d0c>:44: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  hi_small_pred_1.rename(columns={'Account2': 'from_account', 'Account4': 'to_account', 'Is Laundering': 'Actual_Is_Laundering', 'predicciones': 'Predicted_Is_Laundering'}, inplace=True)\n","<ipython-input-10-0b9dcdcb6d0c>:45: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  hi_small_pred_1.drop(columns=['Year', 'Month', 'Day', 'Hour', 'Minute'], inplace=True)\n","<ipython-input-10-0b9dcdcb6d0c>:56: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  hi_small_pred_0_16000[col] = le.inverse_transform(hi_small_pred_0_16000[col])\n","<ipython-input-10-0b9dcdcb6d0c>:56: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  hi_small_pred_0_16000[col] = le.inverse_transform(hi_small_pred_0_16000[col])\n","<ipython-input-10-0b9dcdcb6d0c>:56: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  hi_small_pred_0_16000[col] = le.inverse_transform(hi_small_pred_0_16000[col])\n","<ipython-input-10-0b9dcdcb6d0c>:56: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  hi_small_pred_0_16000[col] = le.inverse_transform(hi_small_pred_0_16000[col])\n","<ipython-input-10-0b9dcdcb6d0c>:56: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  hi_small_pred_0_16000[col] = le.inverse_transform(hi_small_pred_0_16000[col])\n","<ipython-input-10-0b9dcdcb6d0c>:56: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  hi_small_pred_0_16000[col] = le.inverse_transform(hi_small_pred_0_16000[col])\n","<ipython-input-10-0b9dcdcb6d0c>:56: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  hi_small_pred_0_16000[col] = le.inverse_transform(hi_small_pred_0_16000[col])\n","<ipython-input-10-0b9dcdcb6d0c>:58: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  hi_small_pred_0_16000.rename(columns={'Account2': 'from_account', 'Account4': 'to_account', 'Is Laundering': 'Actual_Is_Laundering', 'predicciones': 'Predicted_Is_Laundering'}, inplace=True)\n","<ipython-input-10-0b9dcdcb6d0c>:59: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  hi_small_pred_0_16000.drop(columns=['Year', 'Month', 'Day', 'Hour', 'Minute'], inplace=True)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_77772754-0ab5-42fa-bb66-3e8374b09f1f\", \"filtered_transactions_20240919_100950.json\", 4869315)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["El archivo JSON 'filtered_transactions_20240919_100950.json' ha sido generado y descargado.\n"]}]},{"cell_type":"code","source":["# Cargar el dataset y el modelo\n","hi_small = pd.read_csv('hi_small.csv')"],"metadata":{"id":"SuSoaqWfvY02","executionInfo":{"status":"ok","timestamp":1726740272680,"user_tz":-120,"elapsed":260,"user":{"displayName":"CortexAi","userId":"17341151088591981016"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["print(hi_small.head())  # Para ver las primeras filas del DataFrame\n","print(hi_small.columns)  # Para ver todas las columnas disponibles\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0_w2k4qrvPnn","executionInfo":{"status":"ok","timestamp":1726740274278,"user_tz":-120,"elapsed":268,"user":{"displayName":"CortexAi","userId":"17341151088591981016"}},"outputId":"4b183876-3146-4740-da90-fa2a46cbdc76"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Empty DataFrame\n","Columns: [<!DOCTYPE html><html><head><title>Google Drive - Virus scan warning</title><meta http-equiv=\"content-type\" content=\"text/html; charset=utf-8\"/><style nonce=\"80VdaYj7Y_pRnLKDv-DRxg\">.goog-link-button{position:relative;color:#15c;text-decoration:underline;cursor:pointer}.goog-link-button-disabled{color:#ccc;text-decoration:none;cursor:default}body{color:#222;font:normal 13px/1.4 arial, sans-serif;margin:0}.grecaptcha-badge{visibility:hidden}.uc-main{padding-top:50px;text-align:center}#uc-dl-icon{display:inline-block;margin-top:16px;padding-right:1em;vertical-align:top}#uc-text{display:inline-block;max-width:68ex;text-align:left}.uc-error-caption, .uc-warning-caption{color:#222;font-size:16px}#uc-download-link{text-decoration:none}.uc-name-size a{color:#15c;text-decoration:none}.uc-name-size a:visited{color:#61c;text-decoration:none}.uc-name-size a:active{color:#d14836;text-decoration:none}.uc-footer{color:#777;font-size:11px;padding-bottom:5ex;padding-top:5ex;text-align:center}.uc-footer a{color:#15c}.uc-footer a:visited{color:#61c}.uc-footer a:active{color:#d14836}.uc-footer-divider{color:#ccc;width:100%}.goog-inline-block{position:relative;display:-moz-inline-box;display:inline-block}* html .goog-inline-block{display:inline}*:first-child+html .goog-inline-block{display:inline}sentinel{}</style><link rel=\"icon\" href=\"//ssl.gstatic.com/docs/doclist/images/drive_2022q3_32dp.png\"/></head><body><div class=\"uc-main\"><div id=\"uc-dl-icon\" class=\"image-container\"><div class=\"drive-sprite-aux-download-file\"></div></div><div id=\"uc-text\"><p class=\"uc-warning-caption\">Google Drive can't scan this file for viruses.</p><p class=\"uc-warning-subcaption\"><span class=\"uc-name-size\"><a href=\"/open?id=1fDw0plQy898cw5aPZ8qBfP61djO6ssDH\">HI-Small_Trans.csv</a> (454M)</span> is too large for Google to scan for viruses. Would you still like to download this file?</p><form id=\"download-form\" action=\"https://drive.usercontent.google.com/download\" method=\"get\"><input type=\"submit\" id=\"uc-download-link\" class=\"goog-inline-block jfk-button jfk-button-action\" value=\"Download anyway\"/><input type=\"hidden\" name=\"id\" value=\"1fDw0plQy898cw5aPZ8qBfP61djO6ssDH\"><input type=\"hidden\" name=\"export\" value=\"download\"><input type=\"hidden\" name=\"confirm\" value=\"t\"><input type=\"hidden\" name=\"uuid\" value=\"b92cdc2e-e351-4dd3-b3ba-196ce6969eb4\"></form></div></div><div class=\"uc-footer\"><hr class=\"uc-footer-divider\"></div></body></html>]\n","Index: []\n","Index(['<!DOCTYPE html><html><head><title>Google Drive - Virus scan warning</title><meta http-equiv=\"content-type\" content=\"text/html; charset=utf-8\"/><style nonce=\"80VdaYj7Y_pRnLKDv-DRxg\">.goog-link-button{position:relative;color:#15c;text-decoration:underline;cursor:pointer}.goog-link-button-disabled{color:#ccc;text-decoration:none;cursor:default}body{color:#222;font:normal 13px/1.4 arial',\n","       'sans-serif;margin:0}.grecaptcha-badge{visibility:hidden}.uc-main{padding-top:50px;text-align:center}#uc-dl-icon{display:inline-block;margin-top:16px;padding-right:1em;vertical-align:top}#uc-text{display:inline-block;max-width:68ex;text-align:left}.uc-error-caption',\n","       '.uc-warning-caption{color:#222;font-size:16px}#uc-download-link{text-decoration:none}.uc-name-size a{color:#15c;text-decoration:none}.uc-name-size a:visited{color:#61c;text-decoration:none}.uc-name-size a:active{color:#d14836;text-decoration:none}.uc-footer{color:#777;font-size:11px;padding-bottom:5ex;padding-top:5ex;text-align:center}.uc-footer a{color:#15c}.uc-footer a:visited{color:#61c}.uc-footer a:active{color:#d14836}.uc-footer-divider{color:#ccc;width:100%}.goog-inline-block{position:relative;display:-moz-inline-box;display:inline-block}* html .goog-inline-block{display:inline}*:first-child+html .goog-inline-block{display:inline}sentinel{}</style><link rel=\"icon\" href=\"//ssl.gstatic.com/docs/doclist/images/drive_2022q3_32dp.png\"/></head><body><div class=\"uc-main\"><div id=\"uc-dl-icon\" class=\"image-container\"><div class=\"drive-sprite-aux-download-file\"></div></div><div id=\"uc-text\"><p class=\"uc-warning-caption\">Google Drive can't scan this file for viruses.</p><p class=\"uc-warning-subcaption\"><span class=\"uc-name-size\"><a href=\"/open?id=1fDw0plQy898cw5aPZ8qBfP61djO6ssDH\">HI-Small_Trans.csv</a> (454M)</span> is too large for Google to scan for viruses. Would you still like to download this file?</p><form id=\"download-form\" action=\"https://drive.usercontent.google.com/download\" method=\"get\"><input type=\"submit\" id=\"uc-download-link\" class=\"goog-inline-block jfk-button jfk-button-action\" value=\"Download anyway\"/><input type=\"hidden\" name=\"id\" value=\"1fDw0plQy898cw5aPZ8qBfP61djO6ssDH\"><input type=\"hidden\" name=\"export\" value=\"download\"><input type=\"hidden\" name=\"confirm\" value=\"t\"><input type=\"hidden\" name=\"uuid\" value=\"b92cdc2e-e351-4dd3-b3ba-196ce6969eb4\"></form></div></div><div class=\"uc-footer\"><hr class=\"uc-footer-divider\"></div></body></html>'],\n","      dtype='object')\n"]}]},{"cell_type":"markdown","source":["Finalmente, se guardan los resultados en formato JSON para poder utilizarlos correctamente en la plataforma"],"metadata":{"id":"2F8lVwlLX84j"}},{"cell_type":"code","source":["# Filter 50% of Medium Priority and 50% of Normal Priority\n","medium_priority_df = transactions_filtered[transactions_filtered['priority'] == 'Medium Priority']\n","normal_priority_df = transactions_filtered[transactions_filtered['priority'] == 'Normal Priority']\n","\n","# Ensure that there are at least 450 transactions in each category, if not, take all available\n","medium_priority_sample = medium_priority_df.sample(n=min(450, len(medium_priority_df)), random_state=42)\n","normal_priority_sample = normal_priority_df.sample(n=min(450, len(normal_priority_df)), random_state=42)\n","\n","# Combine the samples\n","final_sample_df = pd.concat([medium_priority_sample, normal_priority_sample])\n","\n","# Check if we have 900 records; if less, adjust or log it\n","if len(final_sample_df) < 900:\n","    print(f\"Warning: The combined dataset has {len(final_sample_df)} records instead of 900 due to insufficient data.\")\n","\n","# Export the smaller dataset to a new JSON file\n","output_json_sample_path = f'/content/drive/MyDrive/TFM - Entregable/smaller_filtered_transactions_{current_time}.json'\n","\n","# Save the smaller dataset\n","final_sample_df.to_json(output_json_sample_path, orient='records', lines=False)\n","\n","# Print confirmation\n","print(f\"Dataset with exported to {output_json_sample_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QkwrQ5BekrQQ","executionInfo":{"status":"ok","timestamp":1726703938607,"user_tz":-120,"elapsed":388,"user":{"displayName":"CortexAi","userId":"17341151088591981016"}},"outputId":"8f1c62db-2fce-43cd-d755-759a498d5b3b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Warning: The combined dataset has 625 records instead of 900 due to insufficient data.\n","Smaller dataset with 900 transactions exported to /content/drive/MyDrive/TFM - Entregable/smaller_filtered_transactions_20240918_235425.json\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"4UZyNecUkyje"},"execution_count":null,"outputs":[]}]}