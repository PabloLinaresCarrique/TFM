{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Notebook alternativo al Docker y SQL automatizado:"],"metadata":{"id":"k6uEZ5KDZzVC"}},{"cell_type":"markdown","source":["Este notebook funciona como una alternativa a la prepración de los datos para utilizarlos en la plataforma."],"metadata":{"id":"FSwjcaViaOY-"}},{"cell_type":"markdown","source":["---"],"metadata":{"id":"SNFY5YRlbHeT"}},{"cell_type":"markdown","source":["## Funcionamiento de la herramienta:"],"metadata":{"id":"hpL8-tz3bLMh"}},{"cell_type":"markdown","source":["La herramienta esta con el dataset previamente cargado y con una ruta establecida hacia una carpeta de drive por lo que NO se debe de realizar ninguna modificación sobre el mismo simplemente correr el código."],"metadata":{"id":"iRrQmzgjbPTm"}},{"cell_type":"markdown","source":["---"],"metadata":{"id":"2hg1uvqUcahK"}},{"cell_type":"markdown","source":["## Construcción del código:"],"metadata":{"id":"Cv0wNGukcPkT"}},{"cell_type":"markdown","source":["Importación de librerias"],"metadata":{"id":"uwGLIBmnciKV"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"62cHypfdNpyU","executionInfo":{"status":"ok","timestamp":1726772240451,"user_tz":-120,"elapsed":3492,"user":{"displayName":"CortexAi","userId":"17341151088591981016"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import pickle\n","import datetime\n","import gdown\n","from google.colab import files"]},{"cell_type":"markdown","source":["Se hace una conexión con drive y se seleeciona directamente el dataset comentado anteriormente:\n","*  HI-Small_Trans.csv\n","\n","A su vez, se carga el modelo guardado en un archivo .pkl, llamado\n","*  model_xgb_optimized.pkl"],"metadata":{"id":"yV4YtHrlcux8"}},{"cell_type":"code","source":["# Descargar el dataset utilizando gdown\n","file_id = '1fDw0plQy898cw5aPZ8qBfP61djO6ssDH'\n","gdown.download(f'https://drive.google.com/uc?export=download&id={file_id}', 'hi_small.csv', quiet=False)\n","\n","# Descargar el modelo utilizando gdown\n","model_file_id = '1p593_b7-TkBAFzfOoEuXfg3jsDD1jyjw'\n","gdown.download(f'https://drive.google.com/uc?export=download&id={model_file_id}', 'model_xgb_optimized.pkl', quiet=False)\n","\n","# Descargar los label encoders utilizando gdown\n","encoders_file_id = '1fi9D8-UYu541eiHGDWugnat1Vavd9a3h'\n","gdown.download(f'https://drive.google.com/uc?export=download&id={encoders_file_id}', 'label_encoders1.pkl', quiet=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":261},"id":"BnZrz8n5NrtD","outputId":"fe493014-a94a-4a39-a5c9-e3445fd20497","executionInfo":{"status":"ok","timestamp":1726772261229,"user_tz":-120,"elapsed":18845,"user":{"displayName":"CortexAi","userId":"17341151088591981016"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading...\n","From (original): https://drive.google.com/uc?export=download&id=1fDw0plQy898cw5aPZ8qBfP61djO6ssDH\n","From (redirected): https://drive.google.com/uc?export=download&id=1fDw0plQy898cw5aPZ8qBfP61djO6ssDH&confirm=t&uuid=0e4e6127-25ac-4aec-b176-5fa42408d823\n","To: /content/hi_small.csv\n","100%|██████████| 476M/476M [00:04<00:00, 95.9MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?export=download&id=1p593_b7-TkBAFzfOoEuXfg3jsDD1jyjw\n","To: /content/model_xgb_optimized.pkl\n","100%|██████████| 923k/923k [00:00<00:00, 62.2MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?export=download&id=1fi9D8-UYu541eiHGDWugnat1Vavd9a3h\n","To: /content/label_encoders1.pkl\n","100%|██████████| 71.7M/71.7M [00:00<00:00, 76.7MB/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["'label_encoders1.pkl'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["En esta parte, preparamos los datos aplicandole los label encorders al dataset.\n","\n"," Tanto a los positivos como a los negativos, posteriormente los añadimos en el mismo dataset para crear uno único. En este único, aplicamos las predicciones y las reglas SQL predefinidas. Una vez que las tenemos, utilizamos un sistema de prioridades pra los analistas, quedando asi:\n","\n"," El sistema de prioridades quedaría así:\n","\n","*   Prioridad 1: SQL + modelo             1/1\n","*   Prioridad 2:  Solo SQL detecta        1/0\n","*   Prioridad 3: Solo detecta modelo    0/1\n","\n","\n","\n"],"metadata":{"id":"m19cPEVie5aY"}},{"cell_type":"code","source":["\n","# Cargar el dataset y el modelo\n","hi_small = pd.read_csv('hi_small.csv')\n","\n","modelo_path = 'model_xgb_optimized.pkl'\n","with open(modelo_path, 'rb') as file:\n","    model = pickle.load(file)\n","\n","# Preparación de datos para aplicar label encoders\n","hi_small['Timestamp'] = pd.to_datetime(hi_small['Timestamp'])\n","\n","hi_small['Year'] = hi_small['Timestamp'].dt.year\n","hi_small['Month'] = hi_small['Timestamp'].dt.month\n","hi_small['Day'] = hi_small['Timestamp'].dt.day\n","hi_small['Hour'] = hi_small['Timestamp'].dt.hour\n","hi_small['Minute'] = hi_small['Timestamp'].dt.minute\n","\n","hi_small.drop(columns=['Timestamp'], inplace=True)\n","hi_small.rename(columns={'Account': 'Account2', 'Account.1': 'Account4'}, inplace=True)\n","\n","# Cargar los label encoders\n","path_to_encoders = 'label_encoders1.pkl'\n","with open(path_to_encoders, 'rb') as f:\n","    label_encoders = pickle.load(f)\n","\n","# Aplicación de los labels encoders\n","for col, le in label_encoders.items():\n","    if col in hi_small.columns:\n","        hi_small[col] = le.transform(hi_small[col])\n","\n","X = hi_small.drop(columns=['Is Laundering'])\n","predicciones = model.predict(X)\n","\n","# Filtro de predicciones de 1\n","hi_small['predicciones'] = predicciones\n","hi_small_pred_1 = hi_small[hi_small['predicciones'] == 1]\n","\n","# Aplicación inversa de predicciones = 1\n","with open(path_to_encoders, 'rb') as f:\n","    label_encoders = pickle.load(f)\n","for col, le in label_encoders.items():\n","    if col in hi_small_pred_1.columns:\n","        hi_small_pred_1[col] = le.inverse_transform(hi_small_pred_1[col])\n","\n","hi_small_pred_1.rename(columns={'Account2': 'from_account', 'Account4': 'to_account', 'Is Laundering': 'Actual_Is_Laundering', 'predicciones': 'Predicted_Is_Laundering'}, inplace=True)\n","hi_small_pred_1.drop(columns=['Year', 'Month', 'Day', 'Hour', 'Minute'], inplace=True)\n","\n","# Filtro de predicciones de 0\n","hi_small_pred_0 = hi_small[hi_small['predicciones'] == 0]\n","hi_small_pred_0_16000 = hi_small_pred_0.head(16000)\n","\n","# Aplicación inversa de predicciones = 0\n","with open(path_to_encoders, 'rb') as f:\n","    label_encoders = pickle.load(f)\n","for col, le in label_encoders.items():\n","    if col in hi_small_pred_0_16000.columns:\n","        hi_small_pred_0_16000[col] = le.inverse_transform(hi_small_pred_0_16000[col])\n","\n","hi_small_pred_0_16000.rename(columns={'Account2': 'from_account', 'Account4': 'to_account', 'Is Laundering': 'Actual_Is_Laundering', 'predicciones': 'Predicted_Is_Laundering'}, inplace=True)\n","hi_small_pred_0_16000.drop(columns=['Year', 'Month', 'Day', 'Hour', 'Minute'], inplace=True)\n","\n","# Combinación de los dataset\n","combined_df = pd.concat([hi_small_pred_1, hi_small_pred_0_16000])\n","combined_df.columns = combined_df.columns.str.strip().str.replace(' ', '_').str.lower()\n","transactions = combined_df.drop(\"actual_is_laundering\", axis=1)\n","\n","# Reglas de SQL\n","def apply_aml_rules(df):\n","    rules = [\n","        {\n","            \"name\": \"Cash Reporting Circumvention\",\n","            \"condition\": \"(payment_currency in ['Euro', 'US Dollar']) and (payment_format == 'Cash') and (9800 <= amount_paid <= 9999.99)\"\n","        },\n","        {\n","            \"name\": \"Exotic Currencies to Cash\",\n","            \"condition\": \"(payment_currency in ['Shekel', 'Mexican Peso', 'Brazilian Real']) and (payment_format in ['Cheque', 'Cash', 'Wire']) and (amount_paid >= 90000)\"\n","        },\n","        {\n","            \"name\": \"High Value Bitcoin to/from Cash\",\n","            \"condition\": \"((receiving_currency == 'Bitcoin') or (payment_currency == 'Bitcoin')) and (amount_paid > 35000)\"\n","        },\n","        {\n","            \"name\": \"Exotic Currencies to/from Bitcoin\",\n","            \"condition\": \"(((receiving_currency in ['Mexican Peso', 'Ruble']) and (payment_currency == 'Bitcoin')) or ((receiving_currency == 'Bitcoin') and (payment_currency in ['Mexican Peso', 'Ruble']))) and (amount_paid > 150000)\"\n","        },\n","        {\n","            \"name\": \"High Value Cheque Payments\",\n","            \"condition\": \"(payment_format == 'Cheque') and (amount_paid > 1000000)\"\n","        },\n","        {\n","            \"name\": \"High Value Wire Payments\",\n","            \"condition\": \"(payment_format == 'Wire') and (amount_paid > 5000000)\"\n","        }\n","    ]\n","\n","    df['sql_is_laundering'] = 0\n","\n","    for rule in rules:\n","        df.loc[df.eval(rule['condition']), 'sql_is_laundering'] = 1\n","\n","    return df\n","\n","# Aplicación de las reglas sobre el dataset\n","transactions = apply_aml_rules(transactions)\n","\n","# Asignación de las prioridades\n","def assign_priority(row):\n","    if row['predicted_is_laundering'] == 1 and row['sql_is_laundering'] == 0:\n","        return 'Medium Priority'\n","    elif row['predicted_is_laundering'] == 0 and row['sql_is_laundering'] == 1:\n","        return 'Normal Priority'\n","    elif row['predicted_is_laundering'] == 1 and row['sql_is_laundering'] == 1:\n","        return 'High Priority'\n","    else:\n","        return 'Low Priority'\n","\n","transactions['priority'] = transactions.apply(assign_priority, axis=1)\n","transactions_filtered = transactions[(transactions['predicted_is_laundering'] != 0) | (transactions['sql_is_laundering'] != 0)]\n","\n","# Exportar el JSON al local\n","output_json_filename = f'filtered_transactions_{datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.json'\n","transactions_filtered.to_json(output_json_filename, orient='records', lines=False)\n","\n","# Descargar el archivo JSON al local\n","\n","files.download(output_json_filename)\n","\n","# Confirmación\n","print(f\"El archivo JSON '{output_json_filename}' ha sido generado y descargado.\")\n"],"metadata":{"id":"0c6JPwToSpb5","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"148b2d14-2c59-4404-e2c6-88a6123052b5","executionInfo":{"status":"ok","timestamp":1726772519037,"user_tz":-120,"elapsed":74896,"user":{"displayName":"CortexAi","userId":"17341151088591981016"}}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-3-ec1f89c83282>:42: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  hi_small_pred_1[col] = le.inverse_transform(hi_small_pred_1[col])\n","<ipython-input-3-ec1f89c83282>:42: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  hi_small_pred_1[col] = le.inverse_transform(hi_small_pred_1[col])\n","<ipython-input-3-ec1f89c83282>:42: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  hi_small_pred_1[col] = le.inverse_transform(hi_small_pred_1[col])\n","<ipython-input-3-ec1f89c83282>:42: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  hi_small_pred_1[col] = le.inverse_transform(hi_small_pred_1[col])\n","<ipython-input-3-ec1f89c83282>:42: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  hi_small_pred_1[col] = le.inverse_transform(hi_small_pred_1[col])\n","<ipython-input-3-ec1f89c83282>:42: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  hi_small_pred_1[col] = le.inverse_transform(hi_small_pred_1[col])\n","<ipython-input-3-ec1f89c83282>:42: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  hi_small_pred_1[col] = le.inverse_transform(hi_small_pred_1[col])\n","<ipython-input-3-ec1f89c83282>:44: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  hi_small_pred_1.rename(columns={'Account2': 'from_account', 'Account4': 'to_account', 'Is Laundering': 'Actual_Is_Laundering', 'predicciones': 'Predicted_Is_Laundering'}, inplace=True)\n","<ipython-input-3-ec1f89c83282>:45: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  hi_small_pred_1.drop(columns=['Year', 'Month', 'Day', 'Hour', 'Minute'], inplace=True)\n","<ipython-input-3-ec1f89c83282>:56: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  hi_small_pred_0_16000[col] = le.inverse_transform(hi_small_pred_0_16000[col])\n","<ipython-input-3-ec1f89c83282>:56: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  hi_small_pred_0_16000[col] = le.inverse_transform(hi_small_pred_0_16000[col])\n","<ipython-input-3-ec1f89c83282>:56: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  hi_small_pred_0_16000[col] = le.inverse_transform(hi_small_pred_0_16000[col])\n","<ipython-input-3-ec1f89c83282>:56: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  hi_small_pred_0_16000[col] = le.inverse_transform(hi_small_pred_0_16000[col])\n","<ipython-input-3-ec1f89c83282>:56: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  hi_small_pred_0_16000[col] = le.inverse_transform(hi_small_pred_0_16000[col])\n","<ipython-input-3-ec1f89c83282>:56: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  hi_small_pred_0_16000[col] = le.inverse_transform(hi_small_pred_0_16000[col])\n","<ipython-input-3-ec1f89c83282>:56: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  hi_small_pred_0_16000[col] = le.inverse_transform(hi_small_pred_0_16000[col])\n","<ipython-input-3-ec1f89c83282>:58: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  hi_small_pred_0_16000.rename(columns={'Account2': 'from_account', 'Account4': 'to_account', 'Is Laundering': 'Actual_Is_Laundering', 'predicciones': 'Predicted_Is_Laundering'}, inplace=True)\n","<ipython-input-3-ec1f89c83282>:59: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  hi_small_pred_0_16000.drop(columns=['Year', 'Month', 'Day', 'Hour', 'Minute'], inplace=True)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_845228b0-fbd4-4f3f-bfd6-4518d97702c3\", \"filtered_transactions_20240919_190156.json\", 4869315)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["El archivo JSON 'filtered_transactions_20240919_190156.json' ha sido generado y descargado.\n"]}]},{"cell_type":"markdown","source":["Finalmente, se guardan los resultados en formato JSON para poder utilizarlos correctamente en la plataforma"],"metadata":{"id":"2F8lVwlLX84j"}}]}